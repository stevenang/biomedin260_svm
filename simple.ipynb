{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Jupyter notebook sample"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f472a22e0a7adfc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:55.021527Z",
     "start_time": "2025-04-22T23:39:54.662176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "7df9140457caed5e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data Definition\n",
    "\n",
    "This defined the feature_data_location"
   ],
   "id": "2e44cfe2f556cba1"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:55.025527Z",
     "start_time": "2025-04-22T23:39:55.023845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Defining data for the dataframe\n",
    "data_paths = {\n",
    "    \"aseg_volumes\": \"data/aseg_volumes.txt\",\n",
    "    \"lh_area\": \"data/lh_area.txt\",\n",
    "    \"lh_thickness\": \"data/lh_thickness.txt\",\n",
    "    \"lh_volume\": \"data/lh_volume.txt\",\n",
    "    \"rh_area\": \"data/rh_area.txt\",\n",
    "    \"rh_thickness\": \"data/rh_thickness.txt\",\n",
    "    \"rh_volume\": \"data/rh_volume.txt\"\n",
    "}\n",
    "#\n",
    "data_frames = {}"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Reading each file to dataframe",
   "id": "3b1f3152ef475ca1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:55.083230Z",
     "start_time": "2025-04-22T23:39:55.074731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for key, path in data_paths.items():\n",
    "    try:\n",
    "        print(f'Reading {path}')\n",
    "        df = pd.read_csv(path, sep=\"\\t\")\n",
    "        df.columns = [col.lower().replace('-', '_') for col in df.columns]\n",
    "        df.set_index('subject_id', inplace=True)\n",
    "        data_frames[key] = df\n",
    "    except Exception as e:\n",
    "        print(e.with_traceback)"
   ],
   "id": "6a5000d63c227c65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data/aseg_volumes.txt\n",
      "Reading data/lh_area.txt\n",
      "Reading data/lh_thickness.txt\n",
      "Reading data/lh_volume.txt\n",
      "Reading data/rh_area.txt\n",
      "Reading data/rh_thickness.txt\n",
      "Reading data/rh_volume.txt\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:55.097860Z",
     "start_time": "2025-04-22T23:39:55.091619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge with remaining dataframes, specifying unique suffixes for each merge\n",
    "suffixes_map = {\n",
    "    'aseg_volumes': '_aseg',\n",
    "    'lh_area': '_lh_area',\n",
    "    'lh_thickness': '_lh_thick',\n",
    "    'lh_volume': '_lh_vol',\n",
    "    'rh_area': '_rh_area',\n",
    "    'rh_thickness': '_rh_thick',\n",
    "    'rh_volume': '_rh_vol'\n",
    "}\n",
    "\n",
    "combined_feature_df = list(data_frames.values())[0]\n",
    "\n",
    "# Skip the first dataframe since it's already in combined_df\n",
    "for key, df in list(data_frames.items())[1:]:\n",
    "    try:\n",
    "        # Use unique suffixes for each merge\n",
    "        combined_feature_df = pd.merge(\n",
    "            combined_feature_df,\n",
    "            df,\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how='outer',\n",
    "            suffixes=('', suffixes_map[key])  # Empty string for left, unique suffix for right\n",
    "        )\n",
    "        print(f\"Merged {key} into combined dataframe\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error merging {key}: {e}\")\n",
    "\n",
    "# Sort by subject_id\n",
    "combined_feature_df = combined_feature_df.sort_values(by='subject_id')"
   ],
   "id": "fca0ec239f641669",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged lh_area into combined dataframe\n",
      "Merged lh_thickness into combined dataframe\n",
      "Merged lh_volume into combined dataframe\n",
      "Merged rh_area into combined dataframe\n",
      "Merged rh_thickness into combined dataframe\n",
      "Merged rh_volume into combined dataframe\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:55.115570Z",
     "start_time": "2025-04-22T23:39:55.107664Z"
    }
   },
   "cell_type": "code",
   "source": "combined_feature_df.head()",
   "id": "ac28bee71bd0cc7c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             left_lateral_ventricle  left_inf_lat_vent  \\\n",
       "subject_id                                               \n",
       "sub-0010033                  3530.3              362.4   \n",
       "sub-0010039                  3788.8              608.4   \n",
       "sub-0010058                  5322.1              553.4   \n",
       "sub-0010062                  5852.3              663.3   \n",
       "sub-0010069                  5430.5              681.1   \n",
       "\n",
       "             left_cerebellum_white_matter  left_cerebellum_cortex  \\\n",
       "subject_id                                                          \n",
       "sub-0010033                       14119.1                 59849.2   \n",
       "sub-0010039                       14945.3                 57459.8   \n",
       "sub-0010058                       14231.3                 64201.8   \n",
       "sub-0010062                       19846.8                 65733.1   \n",
       "sub-0010069                       16942.4                 63117.5   \n",
       "\n",
       "             left_thalamus  left_caudate  left_putamen  left_pallidum  \\\n",
       "subject_id                                                              \n",
       "sub-0010033         7626.0        4328.3        5889.7         1710.6   \n",
       "sub-0010039         6921.0        3779.0        5825.4         1660.8   \n",
       "sub-0010058         6967.5        4217.1        6774.6         1788.3   \n",
       "sub-0010062         9516.1        5000.9        6827.0         2237.7   \n",
       "sub-0010069         8503.8        4345.0        6176.3         1999.5   \n",
       "\n",
       "             3rd_ventricle  4th_ventricle  ...  rh_superiorfrontal_volume  \\\n",
       "subject_id                                 ...                              \n",
       "sub-0010033          778.9         2239.4  ...                    15798.0   \n",
       "sub-0010039          634.0         1365.9  ...                    14540.0   \n",
       "sub-0010058          716.9         2270.6  ...                    16420.0   \n",
       "sub-0010062          833.8         1495.2  ...                    14379.0   \n",
       "sub-0010069          838.0         1772.8  ...                    15461.0   \n",
       "\n",
       "             rh_superiorparietal_volume  rh_superiortemporal_volume  \\\n",
       "subject_id                                                            \n",
       "sub-0010033                     13952.0                     12314.0   \n",
       "sub-0010039                     14238.0                     10740.0   \n",
       "sub-0010058                     15134.0                     13824.0   \n",
       "sub-0010062                     13727.0                     11240.0   \n",
       "sub-0010069                     12962.0                     12447.0   \n",
       "\n",
       "             rh_supramarginal_volume  rh_frontalpole_volume  \\\n",
       "subject_id                                                    \n",
       "sub-0010033                   1368.0                 2102.0   \n",
       "sub-0010039                   1582.0                 2606.0   \n",
       "sub-0010058                   1740.0                 2171.0   \n",
       "sub-0010062                   1218.0                 2167.0   \n",
       "sub-0010069                   1590.0                 3036.0   \n",
       "\n",
       "             rh_temporalpole_volume  rh_transversetemporal_volume  \\\n",
       "subject_id                                                          \n",
       "sub-0010033                  1080.0                        6485.0   \n",
       "sub-0010039                   930.0                        6174.0   \n",
       "sub-0010058                  1026.0                        6894.0   \n",
       "sub-0010062                  1207.0                        7221.0   \n",
       "sub-0010069                  1127.0                        6309.0   \n",
       "\n",
       "             rh_insula_volume  brainsegvolnotvent_rh_vol  etiv_rh_vol  \n",
       "subject_id                                                             \n",
       "sub-0010033         1154368.0               1.555280e+06          NaN  \n",
       "sub-0010039         1140274.0               1.541012e+06          NaN  \n",
       "sub-0010058         1256986.0               1.691810e+06          NaN  \n",
       "sub-0010062         1328274.0               1.814578e+06          NaN  \n",
       "sub-0010069         1338835.0               1.864284e+06          NaN  \n",
       "\n",
       "[5 rows x 291 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_lateral_ventricle</th>\n",
       "      <th>left_inf_lat_vent</th>\n",
       "      <th>left_cerebellum_white_matter</th>\n",
       "      <th>left_cerebellum_cortex</th>\n",
       "      <th>left_thalamus</th>\n",
       "      <th>left_caudate</th>\n",
       "      <th>left_putamen</th>\n",
       "      <th>left_pallidum</th>\n",
       "      <th>3rd_ventricle</th>\n",
       "      <th>4th_ventricle</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_superiorfrontal_volume</th>\n",
       "      <th>rh_superiorparietal_volume</th>\n",
       "      <th>rh_superiortemporal_volume</th>\n",
       "      <th>rh_supramarginal_volume</th>\n",
       "      <th>rh_frontalpole_volume</th>\n",
       "      <th>rh_temporalpole_volume</th>\n",
       "      <th>rh_transversetemporal_volume</th>\n",
       "      <th>rh_insula_volume</th>\n",
       "      <th>brainsegvolnotvent_rh_vol</th>\n",
       "      <th>etiv_rh_vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub-0010033</th>\n",
       "      <td>3530.3</td>\n",
       "      <td>362.4</td>\n",
       "      <td>14119.1</td>\n",
       "      <td>59849.2</td>\n",
       "      <td>7626.0</td>\n",
       "      <td>4328.3</td>\n",
       "      <td>5889.7</td>\n",
       "      <td>1710.6</td>\n",
       "      <td>778.9</td>\n",
       "      <td>2239.4</td>\n",
       "      <td>...</td>\n",
       "      <td>15798.0</td>\n",
       "      <td>13952.0</td>\n",
       "      <td>12314.0</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>2102.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>6485.0</td>\n",
       "      <td>1154368.0</td>\n",
       "      <td>1.555280e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0010039</th>\n",
       "      <td>3788.8</td>\n",
       "      <td>608.4</td>\n",
       "      <td>14945.3</td>\n",
       "      <td>57459.8</td>\n",
       "      <td>6921.0</td>\n",
       "      <td>3779.0</td>\n",
       "      <td>5825.4</td>\n",
       "      <td>1660.8</td>\n",
       "      <td>634.0</td>\n",
       "      <td>1365.9</td>\n",
       "      <td>...</td>\n",
       "      <td>14540.0</td>\n",
       "      <td>14238.0</td>\n",
       "      <td>10740.0</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>6174.0</td>\n",
       "      <td>1140274.0</td>\n",
       "      <td>1.541012e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0010058</th>\n",
       "      <td>5322.1</td>\n",
       "      <td>553.4</td>\n",
       "      <td>14231.3</td>\n",
       "      <td>64201.8</td>\n",
       "      <td>6967.5</td>\n",
       "      <td>4217.1</td>\n",
       "      <td>6774.6</td>\n",
       "      <td>1788.3</td>\n",
       "      <td>716.9</td>\n",
       "      <td>2270.6</td>\n",
       "      <td>...</td>\n",
       "      <td>16420.0</td>\n",
       "      <td>15134.0</td>\n",
       "      <td>13824.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>2171.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>6894.0</td>\n",
       "      <td>1256986.0</td>\n",
       "      <td>1.691810e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0010062</th>\n",
       "      <td>5852.3</td>\n",
       "      <td>663.3</td>\n",
       "      <td>19846.8</td>\n",
       "      <td>65733.1</td>\n",
       "      <td>9516.1</td>\n",
       "      <td>5000.9</td>\n",
       "      <td>6827.0</td>\n",
       "      <td>2237.7</td>\n",
       "      <td>833.8</td>\n",
       "      <td>1495.2</td>\n",
       "      <td>...</td>\n",
       "      <td>14379.0</td>\n",
       "      <td>13727.0</td>\n",
       "      <td>11240.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>2167.0</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>7221.0</td>\n",
       "      <td>1328274.0</td>\n",
       "      <td>1.814578e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0010069</th>\n",
       "      <td>5430.5</td>\n",
       "      <td>681.1</td>\n",
       "      <td>16942.4</td>\n",
       "      <td>63117.5</td>\n",
       "      <td>8503.8</td>\n",
       "      <td>4345.0</td>\n",
       "      <td>6176.3</td>\n",
       "      <td>1999.5</td>\n",
       "      <td>838.0</td>\n",
       "      <td>1772.8</td>\n",
       "      <td>...</td>\n",
       "      <td>15461.0</td>\n",
       "      <td>12962.0</td>\n",
       "      <td>12447.0</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>3036.0</td>\n",
       "      <td>1127.0</td>\n",
       "      <td>6309.0</td>\n",
       "      <td>1338835.0</td>\n",
       "      <td>1.864284e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 291 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load demographic data",
   "id": "b0578f9a33ac05b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:55.160880Z",
     "start_time": "2025-04-22T23:39:55.151789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "demographic_data_path = \"data/combined_participants_with_diagnosis.csv\"\n",
    "demographic_dataframe = pd.read_csv(demographic_data_path)\n",
    "# Rename column participant_id to subject_id\n",
    "demographic_dataframe.rename(columns={'participant_id': 'subject_id'}, inplace=True)\n",
    "# Reset index\n",
    "demographic_dataframe.index = demographic_dataframe['subject_id']\n",
    "demographic_dataframe.head()"
   ],
   "id": "f4cf7e7cc81053b2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              subject_id gender  age handedness  verbal_iq      source_folder  \\\n",
       "subject_id                                                                      \n",
       "sub-0000213  sub-0000213      2  NaN       80.0        NaN  ds003500-download   \n",
       "sub-0000214  sub-0000214      2  NaN       95.0        NaN  ds003500-download   \n",
       "sub-0000218  sub-0000218      1  NaN      -90.0        NaN  ds003500-download   \n",
       "sub-0000219  sub-0000219      1  NaN       90.0        NaN  ds003500-download   \n",
       "sub-0000220  sub-0000220      1  NaN       90.0        NaN  ds003500-download   \n",
       "\n",
       "             adhd_index adhd_measure dx  performance_iq  ...  qc_rest_4  \\\n",
       "subject_id                                               ...              \n",
       "sub-0000213         NaN          NaN  0             NaN  ...        NaN   \n",
       "sub-0000214         NaN          NaN  0             NaN  ...        NaN   \n",
       "sub-0000218         NaN          NaN  0             NaN  ...        NaN   \n",
       "sub-0000219         NaN          NaN  1             NaN  ...        NaN   \n",
       "sub-0000220         NaN          NaN  0             NaN  ...        NaN   \n",
       "\n",
       "            hyper_impulsive secondary_dx study_#  secondary_dx  session  \\\n",
       "subject_id                                                                \n",
       "sub-0000213             NaN          NaN     NaN            NaN     NaN   \n",
       "sub-0000214             NaN          NaN     NaN            NaN     NaN   \n",
       "sub-0000218             NaN          NaN     NaN            NaN     NaN   \n",
       "sub-0000219             NaN          NaN     NaN            NaN     NaN   \n",
       "sub-0000220             NaN          NaN     NaN            NaN     NaN   \n",
       "\n",
       "             original_participant_id     diagnosis_status  age_group  \\\n",
       "subject_id                                                             \n",
       "sub-0000213                  sub-213  Typical Development        NaN   \n",
       "sub-0000214                  sub-214  Typical Development        NaN   \n",
       "sub-0000218                  sub-218  Typical Development        NaN   \n",
       "sub-0000219                  sub-219                 ADHD        NaN   \n",
       "sub-0000220                  sub-220  Typical Development        NaN   \n",
       "\n",
       "             gender_std  \n",
       "subject_id               \n",
       "sub-0000213           2  \n",
       "sub-0000214           2  \n",
       "sub-0000218           1  \n",
       "sub-0000219           1  \n",
       "sub-0000220           1  \n",
       "\n",
       "[5 rows x 53 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>handedness</th>\n",
       "      <th>verbal_iq</th>\n",
       "      <th>source_folder</th>\n",
       "      <th>adhd_index</th>\n",
       "      <th>adhd_measure</th>\n",
       "      <th>dx</th>\n",
       "      <th>performance_iq</th>\n",
       "      <th>...</th>\n",
       "      <th>qc_rest_4</th>\n",
       "      <th>hyper_impulsive</th>\n",
       "      <th>secondary_dx</th>\n",
       "      <th>study_#</th>\n",
       "      <th>secondary_dx</th>\n",
       "      <th>session</th>\n",
       "      <th>original_participant_id</th>\n",
       "      <th>diagnosis_status</th>\n",
       "      <th>age_group</th>\n",
       "      <th>gender_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub-0000213</th>\n",
       "      <td>sub-0000213</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ds003500-download</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sub-213</td>\n",
       "      <td>Typical Development</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0000214</th>\n",
       "      <td>sub-0000214</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ds003500-download</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sub-214</td>\n",
       "      <td>Typical Development</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0000218</th>\n",
       "      <td>sub-0000218</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ds003500-download</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sub-218</td>\n",
       "      <td>Typical Development</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0000219</th>\n",
       "      <td>sub-0000219</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ds003500-download</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sub-219</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0000220</th>\n",
       "      <td>sub-0000220</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ds003500-download</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sub-220</td>\n",
       "      <td>Typical Development</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Cleaning Demographic Data",
   "id": "e6aae382babebb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:55.229781Z",
     "start_time": "2025-04-22T23:39:55.227054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_distinct_values(df):\n",
    "    \"\"\"\n",
    "    Prints the distinct values for each column in the DataFrame,\n",
    "    along with their counts and data types.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== COLUMN VALUE ANALYSIS ===\")\n",
    "\n",
    "    for column in df.columns:\n",
    "        # Get the data type\n",
    "        dtype = df[column].dtype\n",
    "\n",
    "        # Count null values\n",
    "        null_count = df[column].isna().sum()\n",
    "        null_percentage = (null_count / len(df)) * 100\n",
    "\n",
    "        print(f\"\\nColumn: {column}\")\n",
    "        print(f\"Data type: {dtype}\")\n",
    "        print(f\"Null values: {null_count} ({null_percentage:.1f}%)\")\n",
    "\n",
    "        # For columns with many distinct values (like age), show statistics instead\n",
    "        unique_count = df[column].nunique()\n",
    "\n",
    "        if unique_count > 10 and pd.api.types.is_numeric_dtype(df[column]):\n",
    "            # For numeric columns with many values, show statistics\n",
    "            print(f\"Unique values: {unique_count}\")\n",
    "            print(f\"Min: {df[column].min()}\")\n",
    "            print(f\"Max: {df[column].max()}\")\n",
    "            print(f\"Mean: {df[column].mean():.2f}\")\n",
    "            print(f\"Median: {df[column].median()}\")\n",
    "        else:\n",
    "            # For columns with fewer unique values or non-numeric types,\n",
    "            # show the actual values and their counts\n",
    "            value_counts = df[column].value_counts(dropna=False).head(15)\n",
    "            print(f\"Unique values: {unique_count}\")\n",
    "            print(\"Value counts (top 15):\")\n",
    "            for value, count in value_counts.items():\n",
    "                percentage = (count / len(df)) * 100\n",
    "                value_display = str(value)\n",
    "                if pd.isna(value):\n",
    "                    value_display = \"NULL/NaN\"\n",
    "                elif value == \"\":\n",
    "                    value_display = \"[empty string]\"\n",
    "                print(f\"  {value_display}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "            # If there are more than 15 unique values, indicate there are more\n",
    "            if unique_count > 15:\n",
    "                print(f\"  ... and {unique_count - 15} more values\")\n"
   ],
   "id": "ec7198330bd6eada",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:55.239373Z",
     "start_time": "2025-04-22T23:39:55.231664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Only select the necessary columns\n",
    "demographic_dataframe = demographic_dataframe.loc[:, ['subject_id', 'gender', 'age', 'dx', 'Age', 'Gender', 'sex', 'diagnosis_status']]\n",
    "\n",
    "# Convert all gender values to lowercase for consistency\n",
    "if demographic_dataframe['gender'].dtype == 'object':\n",
    "    demographic_dataframe['gender'] = demographic_dataframe['gender'].str.lower()\n",
    "\n",
    "# Convert all Gender values to lowercase for consistency\n",
    "if demographic_dataframe['Gender'].dtype == 'object':\n",
    "    demographic_dataframe['Gender'] = demographic_dataframe['Gender'].str.lower()\n",
    "\n",
    "# Convert all Gender values to lowercase for consistency\n",
    "if demographic_dataframe['sex'].dtype == 'object':\n",
    "    demographic_dataframe['sex'] = demographic_dataframe['sex'].str.lower()\n",
    "\n",
    "# Map gender values to 1 (Male) and 2 (Female)\n",
    "gender_mapping = {\n",
    "    'm': 1, 'male': 1, 'man': 1, '1': 1, 1: 1,\n",
    "    'f': 2, 'female': 2, 'woman': 2, '2': 2, 2: 2\n",
    "}\n",
    "\n",
    "demographic_dataframe['gender_code'] = demographic_dataframe['gender'].map(gender_mapping)\n",
    "demographic_dataframe['Gender_code'] = demographic_dataframe['Gender'].map(gender_mapping)\n",
    "demographic_dataframe['sex_code'] = demographic_dataframe['sex'].map(gender_mapping)\n",
    "\n",
    "# Combined gender information\n",
    "# Create a new column that combines gender_code, Gender_code, and sex_code\n",
    "demographic_dataframe['combined_gender_code'] = None\n",
    "\n",
    "# Fill values from each column in order of priority\n",
    "# First try gender_code\n",
    "demographic_dataframe['combined_gender_code'] = demographic_dataframe['gender_code']\n",
    "\n",
    "# Then fill in missing values from Gender_code\n",
    "mask = demographic_dataframe['combined_gender_code'].isna() & ~demographic_dataframe['Gender_code'].isna()\n",
    "demographic_dataframe.loc[mask, 'combined_gender_code'] = demographic_dataframe.loc[mask, 'Gender_code']\n",
    "\n",
    "# Finally fill in missing values from sex_code\n",
    "mask = demographic_dataframe['combined_gender_code'].isna() & ~demographic_dataframe['sex_code'].isna()\n",
    "demographic_dataframe.loc[mask, 'combined_gender_code'] = demographic_dataframe.loc[mask, 'sex_code']\n",
    "\n",
    "# Drop the individual code columns if you want\n",
    "demographic_dataframe = demographic_dataframe.drop(columns=['gender_code', 'Gender_code', 'sex_code', 'gender', 'Gender', 'sex'])\n",
    "\n",
    "# You can rename the combined column to something more concise if needed\n",
    "demographic_dataframe = demographic_dataframe.rename(columns={'combined_gender_code': 'gender'})\n",
    "\n",
    "demographic_dataframe.head()\n",
    "\n",
    "#print_distinct_values(demographic_dataframe)"
   ],
   "id": "fb4e5a93748c738a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              subject_id  age dx  Age     diagnosis_status  gender\n",
       "subject_id                                                        \n",
       "sub-0000213  sub-0000213  NaN  0  NaN  Typical Development     2.0\n",
       "sub-0000214  sub-0000214  NaN  0  NaN  Typical Development     2.0\n",
       "sub-0000218  sub-0000218  NaN  0  NaN  Typical Development     1.0\n",
       "sub-0000219  sub-0000219  NaN  1  NaN                 ADHD     1.0\n",
       "sub-0000220  sub-0000220  NaN  0  NaN  Typical Development     1.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>age</th>\n",
       "      <th>dx</th>\n",
       "      <th>Age</th>\n",
       "      <th>diagnosis_status</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub-0000213</th>\n",
       "      <td>sub-0000213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typical Development</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0000214</th>\n",
       "      <td>sub-0000214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typical Development</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0000218</th>\n",
       "      <td>sub-0000218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typical Development</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0000219</th>\n",
       "      <td>sub-0000219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0000220</th>\n",
       "      <td>sub-0000220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typical Development</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Clean up age",
   "id": "87e8cbbdb3fe29d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:55.317905Z",
     "start_time": "2025-04-22T23:39:55.315047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a new column that combines Age and age\n",
    "demographic_dataframe['combined_age'] = None\n",
    "\n",
    "# Fill values from each column in order of priority\n",
    "# First try age\n",
    "demographic_dataframe['combined_age'] = demographic_dataframe['age']\n",
    "\n",
    "# Then fill in missing values from Age\n",
    "mask = demographic_dataframe['combined_age'].isna() & ~demographic_dataframe['Age'].isna()\n",
    "demographic_dataframe.loc[mask, 'combined_age'] = demographic_dataframe.loc[mask, 'Age']\n",
    "\n",
    "# Make sure age is numeric\n",
    "demographic_dataframe['combined_age'] = pd.to_numeric(demographic_dataframe['combined_age'], errors='coerce')\n",
    "\n",
    "# Drop the individual age columns if you want\n",
    "demographic_dataframe = demographic_dataframe.drop(columns=['age', 'Age'])\n",
    "\n",
    "# You can rename the combined column to the standard name\n",
    "demographic_dataframe = demographic_dataframe.rename(columns={'combined_age': 'age'})"
   ],
   "id": "76cbe212f402441a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Clean up diagnosis",
   "id": "cf47ea9a09a34916"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:55.354823Z",
     "start_time": "2025-04-22T23:39:55.351032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "dx_mapping = {\n",
    "    'Typically Developing Children': 1, 'ADHD-Combined': 1, 'ADHD-Inattentive': 1, 'ADHD-Hyperactive/Impulsive': 1, '1': 1, 1: 1, 'ADHD': 1,\n",
    "    'Typically Developing Children': 0, '0': 0, 0: 0, 'Typical Development': 0\n",
    "}\n",
    "\n",
    "demographic_dataframe['dx_clean'] = demographic_dataframe['dx'].map(dx_mapping)\n",
    "demographic_dataframe['diagnosis_status_clean'] = demographic_dataframe['diagnosis_status'].map(dx_mapping)\n",
    "\n",
    "# Combine the two fields, prioritizing 'dx_clean' if available\n",
    "demographic_dataframe['combined_dx'] = demographic_dataframe['dx_clean'].combine_first(demographic_dataframe['diagnosis_status_clean'])\n",
    "\n",
    "# Optional: If there are still missing values, fill them with a default value (e.g., -1 or NaN)\n",
    "demographic_dataframe['combined_dx'].fillna(np.nan, inplace=True)\n",
    "\n",
    "# Drop intermediate columns if no longer needed\n",
    "demographic_dataframe.drop(['dx_clean', 'diagnosis_status_clean'], axis=1, inplace=True)"
   ],
   "id": "ec28aa1a62ee3342",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vx/61fdjmc15_jfzdhn6pw7sqgc0000gn/T/ipykernel_82518/4285503471.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  demographic_dataframe['combined_dx'].fillna(np.nan, inplace=True)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:55.427427Z",
     "start_time": "2025-04-22T23:39:55.423859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "demographic_dataframe.drop(['dx', 'diagnosis_status'], axis=1, inplace=True)\n",
    "demographic_dataframe.rename(columns={'combined_dx': 'label'}, inplace=True)\n",
    "demographic_dataframe.head()"
   ],
   "id": "a0f00b98126fc89c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              subject_id  gender  age  label\n",
       "subject_id                                  \n",
       "sub-0000213  sub-0000213     2.0  NaN    0.0\n",
       "sub-0000214  sub-0000214     2.0  NaN    0.0\n",
       "sub-0000218  sub-0000218     1.0  NaN    0.0\n",
       "sub-0000219  sub-0000219     1.0  NaN    1.0\n",
       "sub-0000220  sub-0000220     1.0  NaN    0.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub-0000213</th>\n",
       "      <td>sub-0000213</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0000214</th>\n",
       "      <td>sub-0000214</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0000218</th>\n",
       "      <td>sub-0000218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0000219</th>\n",
       "      <td>sub-0000219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0000220</th>\n",
       "      <td>sub-0000220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Combined extracted feature and demographic data",
   "id": "e98754453824d542"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:55.501599Z",
     "start_time": "2025-04-22T23:39:55.489060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_feature = pd.merge(combined_feature_df, demographic_dataframe, left_index=True, right_index=True, how='left')\n",
    "print(final_feature.columns)\n",
    "final_feature.head()\n",
    "\n",
    "# Write the dataframe to a CSV file\n",
    "output_filename = \"data/final_features.csv\"\n",
    "final_feature.to_csv(output_filename, index=True)\n",
    "print(f\"Data successfully written to {output_filename}\")\n"
   ],
   "id": "4f547f9d73c379bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['left_lateral_ventricle', 'left_inf_lat_vent',\n",
      "       'left_cerebellum_white_matter', 'left_cerebellum_cortex',\n",
      "       'left_thalamus', 'left_caudate', 'left_putamen', 'left_pallidum',\n",
      "       '3rd_ventricle', '4th_ventricle',\n",
      "       ...\n",
      "       'rh_frontalpole_volume', 'rh_temporalpole_volume',\n",
      "       'rh_transversetemporal_volume', 'rh_insula_volume',\n",
      "       'brainsegvolnotvent_rh_vol', 'etiv_rh_vol', 'subject_id', 'gender',\n",
      "       'age', 'label'],\n",
      "      dtype='object', length=295)\n",
      "Data successfully written to data/final_features.csv\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Training, Test and Validation Data",
   "id": "d9d0ce96071707cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:56.004929Z",
     "start_time": "2025-04-22T23:39:55.529678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_df = final_feature[final_feature['label'].isna()].copy()\n",
    "train_val_df = final_feature[final_feature['label'].notna()].copy()\n",
    "\n",
    "# Separate features and labels for train/validation\n",
    "X = train_val_df.drop(columns=['subject_id', 'label'])\n",
    "y = train_val_df['label']\n",
    "\n",
    "# Split into training and validation sets (e.g., 80% train, 20% validation)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Prepare test set features (without labels)\n",
    "X_test = test_df.drop(columns=['subject_id', 'label'])\n",
    "y_test = test_df['label']\n",
    "\n",
    "# Display the shapes to verify splits\n",
    "print(f'Train shape: {X_train.shape}, Train labels: {y_train.shape}')\n",
    "print(f'Validation shape: {X_validation.shape}, Validation labels: {y_validation.shape}')\n",
    "print(f'Test shape (no labels): {X_test.shape}, expected labels: {y_test.shape}')"
   ],
   "id": "ec579f232221611",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (58, 293), Train labels: (58,)\n",
      "Validation shape: (20, 293), Validation labels: (20,)\n",
      "Test shape (no labels): (21, 293), expected labels: (21,)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initial ML Model",
   "id": "24109d548b3f5832"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:56.157218Z",
     "start_time": "2025-04-22T23:39:56.031809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Pipeline with imputation and SVC classifier\n",
    "svm_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Mean imputation (can also try median)\n",
    "    ('svc', SVC(kernel='linear', random_state=42))\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation data\n",
    "y_pred_validation = svm_pipeline.predict(X_validation)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_validation, y_pred_validation))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_validation, y_pred_validation))\n"
   ],
   "id": "1303185b670cebe1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.85      0.79        13\n",
      "         1.0       0.60      0.43      0.50         7\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.67      0.64      0.64        20\n",
      "weighted avg       0.69      0.70      0.69        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cross Validation",
   "id": "e7ab58fa16c4f405"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:56.374655Z",
     "start_time": "2025-04-22T23:39:56.182339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define your pipeline\n",
    "svm_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Mean imputation\n",
    "    ('svc', SVC(kernel='linear', random_state=42))\n",
    "])\n",
    "\n",
    "# Define the number of folds (commonly 5 or 10)\n",
    "n_folds = 5\n",
    "\n",
    "# Create a stratified k-fold cross-validator\n",
    "# Stratified ensures that each fold has the same proportion of class labels\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define multiple scoring metrics to evaluate\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='weighted'),\n",
    "    'recall': make_scorer(recall_score, average='weighted'),\n",
    "    'f1': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "# Perform cross-validation with multiple metrics\n",
    "cv_results = cross_validate(\n",
    "    svm_pipeline,\n",
    "    X_train,  # Use your combined training+validation set here\n",
    "    y_train,  # Use your combined training+validation labels here\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Cross-Validation Results ({n_folds} folds):\")\n",
    "print(f\"Accuracy: {cv_results['test_accuracy'].mean():.4f} ± {cv_results['test_accuracy'].std():.4f}\")\n",
    "print(f\"Precision: {cv_results['test_precision'].mean():.4f} ± {cv_results['test_precision'].std():.4f}\")\n",
    "print(f\"Recall: {cv_results['test_recall'].mean():.4f} ± {cv_results['test_recall'].std():.4f}\")\n",
    "print(f\"F1 Score: {cv_results['test_f1'].mean():.4f} ± {cv_results['test_f1'].std():.4f}\")\n",
    "\n",
    "# If you want to see individual fold scores\n",
    "for i, acc in enumerate(cv_results['test_accuracy']):\n",
    "    print(f\"Fold {i+1} Accuracy: {acc:.4f}\")"
   ],
   "id": "3dd7b04730b6e086",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results (5 folds):\n",
      "Accuracy: 0.4818 ± 0.0811\n",
      "Precision: 0.5196 ± 0.0892\n",
      "Recall: 0.4818 ± 0.0811\n",
      "F1 Score: 0.4856 ± 0.0795\n",
      "Fold 1 Accuracy: 0.5833\n",
      "Fold 2 Accuracy: 0.5000\n",
      "Fold 3 Accuracy: 0.4167\n",
      "Fold 4 Accuracy: 0.3636\n",
      "Fold 5 Accuracy: 0.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest",
   "id": "c694267e3e56550a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:56.500477Z",
     "start_time": "2025-04-22T23:39:56.399431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Pipeline with imputation and SVC classifier\n",
    "rf_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Mean imputation (can also try median)\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation data\n",
    "y_pred_validation = rf_pipeline.predict(X_validation)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_validation, y_pred_validation))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_validation, y_pred_validation))"
   ],
   "id": "bfb433fd0e9b136b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.75\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.92      0.83        13\n",
      "         1.0       0.75      0.43      0.55         7\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.75      0.68      0.69        20\n",
      "weighted avg       0.75      0.75      0.73        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest Cross Validation",
   "id": "4dae0c66210c68e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:39:57.098652Z",
     "start_time": "2025-04-22T23:39:56.527435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer, precision_score, recall_score, f1_score\n",
    "\n",
    "# Pipeline with imputation and SVC classifier\n",
    "rf_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Mean imputation (can also try median)\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Define the number of folds (commonly 5 or 10)\n",
    "n_folds = 10\n",
    "\n",
    "# Create a stratified k-fold cross-validator\n",
    "# Stratified ensures that each fold has the same proportion of class labels\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define multiple scoring metrics to evaluate\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='weighted'),\n",
    "    'recall': make_scorer(recall_score, average='weighted'),\n",
    "    'f1': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "# Perform cross-validation with multiple metrics\n",
    "cv_results = cross_validate(\n",
    "    rf_pipeline,\n",
    "    X_train,  # Use your combined training+validation set here\n",
    "    y_train,  # Use your combined training+validation labels here\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Cross-Validation Results ({n_folds} folds):\")\n",
    "print(f\"Accuracy: {cv_results['test_accuracy'].mean():.4f} ± {cv_results['test_accuracy'].std():.4f}\")\n",
    "print(f\"Precision: {cv_results['test_precision'].mean():.4f} ± {cv_results['test_precision'].std():.4f}\")\n",
    "print(f\"Recall: {cv_results['test_recall'].mean():.4f} ± {cv_results['test_recall'].std():.4f}\")\n",
    "print(f\"F1 Score: {cv_results['test_f1'].mean():.4f} ± {cv_results['test_f1'].std():.4f}\")\n",
    "\n",
    "# If you want to see individual fold scores\n",
    "for i, acc in enumerate(cv_results['test_accuracy']):\n",
    "    print(f\"Fold {i+1} Accuracy: {acc:.4f}\")"
   ],
   "id": "4ff2887bec02ba7c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results (10 folds):\n",
      "Accuracy: 0.6900 ± 0.1613\n",
      "Precision: 0.6011 ± 0.2171\n",
      "Recall: 0.6900 ± 0.1613\n",
      "F1 Score: 0.6274 ± 0.1820\n",
      "Fold 1 Accuracy: 0.6667\n",
      "Fold 2 Accuracy: 0.6667\n",
      "Fold 3 Accuracy: 0.6667\n",
      "Fold 4 Accuracy: 0.8333\n",
      "Fold 5 Accuracy: 0.6667\n",
      "Fold 6 Accuracy: 0.6667\n",
      "Fold 7 Accuracy: 0.5000\n",
      "Fold 8 Accuracy: 0.8333\n",
      "Fold 9 Accuracy: 0.4000\n",
      "Fold 10 Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/stevenang/DataspellProjects/biomedin260/venv/lib/python3.13/site-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['etiv' 'etiv_lh_thick' 'etiv_lh_vol' 'etiv_rh_area' 'etiv_rh_thick'\n",
      " 'etiv_rh_vol']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
